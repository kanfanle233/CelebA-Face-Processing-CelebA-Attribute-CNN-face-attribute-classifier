# train.py
import cv2
import numpy as np
from PIL import Image
import os
import matplotlib.pyplot as plt

import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms as T
from tqdm import tqdm

from celeba_utils import load_celeba_full_df, load_image, align_face_by_eyes


# ========== 2. Dataset ç±»å®šä¹‰ï¼ˆæ”¾åœ¨å…¨å±€æ²¡é—®é¢˜ï¼‰ ==========
class CelebAFaceDataset(Dataset):
    def __init__(self, df, target_attrs, image_size=(128, 128), augment=False):
        self.df = df.reset_index(drop=True)
        self.target_attrs = target_attrs
        self.image_size = image_size

        base_tf = [
            T.ToTensor(),
            T.Normalize(mean=[0.5, 0.5, 0.5],
                        std =[0.5, 0.5, 0.5]),
        ]
        if augment:
            self.transform = T.Compose([
                T.RandomHorizontalFlip(p=0.5),
                *base_tf
            ])
        else:
            self.transform = T.Compose(base_tf)

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        img_raw = load_image(row)  # BGR
        face = align_face_by_eyes(img_raw, row, output_size=self.image_size)  # BGR

        face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)
        img_pil = Image.fromarray(face_rgb)
        x = self.transform(img_pil)  # [3,H,W]

        y_vals = row[self.target_attrs].values.astype(np.float32)
        y = torch.from_numpy(y_vals)  # [num_classes]
        return x, y


# ========== 3. å°å‹ CNN å®šä¹‰ï¼ˆä¹Ÿå¯ä»¥å…¨å±€æ”¾ï¼‰ ==========
class SimpleCNN(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.features = nn.Sequential(
            # 3x128x128 -> 32x64x64
            nn.Conv2d(3, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),

            # 32x64x64 -> 64x32x32
            nn.Conv2d(32, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),

            # 64x32x32 -> 128x16x16
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),

            # 128x16x16 -> 256x8x8
            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(256 * 8 * 8, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x  # logits


# ========== ä¸»é€»è¾‘å°è£…åˆ° main() é‡Œï¼Œé¿å… Windows å¤šè¿›ç¨‹æŠ¥é”™ ==========
def main():
    # 0. è®¾å¤‡
    assert torch.cuda.is_available(), "æ²¡æœ‰æ£€æµ‹åˆ° CUDAï¼Œè¯·æ£€æŸ¥ RTX 4060 é©±åŠ¨"
    device = torch.device("cuda:0")
    print("å½“å‰ GPU:", torch.cuda.get_device_name(device))

    # 1. åŠ è½½ full_df
    full_df = load_celeba_full_df()
    print("CelebA æ€»æ ·æœ¬æ•°:", len(full_df))

    # é€‰æ‹©å±æ€§ï¼šæ€§åˆ« + çœ¼é•œ
    target_attrs = ["Male", "Eyeglasses"]
    num_classes = len(target_attrs)

    # -1 / 1 â†’ 0 / 1
    for col in target_attrs:
        full_df[col] = full_df[col].replace({-1: 0, 1: 1})

    # æŒ‰ split åˆ’åˆ† train/valï¼ˆ0=train, 1=valï¼‰
    train_df = full_df[full_df["split"] == 0].reset_index(drop=True)
    val_df   = full_df[full_df["split"] == 1].reset_index(drop=True)
    print("Train size:", len(train_df))
    print("Val size  :", len(val_df))

    # 2. Dataset & DataLoader
    IMAGE_SIZE = (128, 128)
    BATCH_SIZE = 512
    NUM_WORKERS = 4  # Windows ä¸‹å…ˆç”¨ 0ï¼Œæƒ³æé€Ÿå†æ”¹ 4

    train_dataset = CelebAFaceDataset(train_df, target_attrs, IMAGE_SIZE, augment=True)
    val_dataset   = CelebAFaceDataset(val_df,   target_attrs, IMAGE_SIZE, augment=False)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,
                              shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)
    val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE,
                              shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)

    # 3. æ¨¡å‹
    model = SimpleCNN(num_classes).to(device)
    print(model)
    print("å¯è®­ç»ƒå‚æ•°é‡:", sum(p.numel() for p in model.parameters() if p.requires_grad))

    # 4. æŸå¤±ã€ä¼˜åŒ–å™¨
    criterion = nn.BCEWithLogitsLoss()
    # é»˜è®¤å­¦ä¹ ç‡
    lr = 1e-3
    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)

    # 5. éªŒè¯å‡½æ•°ï¼ˆè·Ÿä¹‹å‰ä¸€æ ·ï¼‰
    def evaluate(model, loader):
        model.eval()
        total_loss = 0.0
        total_samples = 0
        correct_per_attr = torch.zeros(num_classes, device=device)

        with torch.no_grad():
            for xb, yb in loader:
                xb, yb = xb.to(device), yb.to(device)

                logits = model(xb)
                loss = criterion(logits, yb)

                total_loss += loss.item() * xb.size(0)
                total_samples += xb.size(0)

                probs = torch.sigmoid(logits)
                preds = (probs > 0.5).float()
                correct_per_attr += (preds == yb).sum(dim=0)

        avg_loss = total_loss / total_samples
        acc_per_attr = (correct_per_attr / total_samples).cpu().numpy()
        return avg_loss, acc_per_attr

    # 6. å¦‚æœå­˜åœ¨ best_model.pthï¼Œå°±åœ¨å®ƒåŸºç¡€ä¸Šç»§ç»­è®­
    best_acc = 0.0
    if os.path.exists("best_model.pth"):
        state_dict = torch.load("best_model.pth", map_location=device)
        model.load_state_dict(state_dict)
        print("âœ… æ£€æµ‹åˆ° best_model.pthï¼Œå·²åŠ è½½æƒé‡ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒã€‚")

        # å¯é€‰ï¼šç»§ç»­è®­ç»ƒæ—¶æŠŠå­¦ä¹ ç‡ç¨å¾®è°ƒä½ä¸€ç‚¹ï¼ˆæ¯”å¦‚ /2ï¼‰
        for g in optimizer.param_groups:
            g["lr"] = lr * 0.5
        print(f"ç»§ç»­è®­ç»ƒï¼Œå­¦ä¹ ç‡è°ƒæ•´ä¸º {lr * 0.5:g}")

        # å…ˆåœ¨ val ä¸Šè¯„ä¼°ä¸€æ¬¡ï¼Œä½œä¸ºå½“å‰ best_acc
        val_loss0, val_acc0 = evaluate(model, val_loader)
        best_acc = float(val_acc0.mean())
        print(f"å½“å‰åŠ è½½æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å¹³å‡å‡†ç¡®ç‡: {best_acc:.4f} (val_loss={val_loss0:.4f})")
    else:
        print("æœªæ‰¾åˆ° best_model.pthï¼Œå°†ä»éšæœºåˆå§‹åŒ–å¼€å§‹è®­ç»ƒã€‚")

    # 7. è®­ç»ƒå¾ªç¯
    EPOCHS = 8  # è¿™é‡Œæ˜¯â€œç»§ç»­è®­ç»ƒâ€çš„ epoch æ•°ï¼Œæ¯”å¦‚å†è®­ 8 è½®
    history = {
        "train_loss": [],
        "val_loss": [],
        "acc": {name: [] for name in target_attrs}
    }

    for epoch in range(1, EPOCHS + 1):
        model.train()
        running_loss = 0.0
        total = 0

        pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{EPOCHS}")
        for xb, yb in pbar:
            xb, yb = xb.to(device), yb.to(device)

            optimizer.zero_grad()
            logits = model(xb)
            loss = criterion(logits, yb)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * xb.size(0)
            total += xb.size(0)

            mem = torch.cuda.memory_allocated(device) / 1024**3
            pbar.set_postfix(loss=running_loss/total, mem=f"{mem:.2f}GB")

        scheduler.step()

        train_loss = running_loss / total
        val_loss, val_acc_attr = evaluate(model, val_loader)

        history["train_loss"].append(train_loss)
        history["val_loss"].append(val_loss)
        for name, acc in zip(target_attrs, val_acc_attr):
            history["acc"][name].append(acc)

        avg_acc = float(val_acc_attr.mean())
        if avg_acc > best_acc:
            best_acc = avg_acc
            torch.save(model.state_dict(), "best_model.pth")
            print(f"ğŸ’¾ æ›´æ–°å¹¶ä¿å­˜æ–°çš„ best_model.pth, å¹³å‡ acc = {best_acc:.4f}")

        acc_str = ", ".join([f"{n}={a:.3f}" for n, a in zip(target_attrs, val_acc_attr)])
        print(f"\n[Epoch {epoch}/{EPOCHS}] "
              f"train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  |  {acc_str}\n")

    print("ç»§ç»­è®­ç»ƒç»“æŸã€‚")
    print("å½“å‰æœ€ä½³éªŒè¯å¹³å‡å‡†ç¡®ç‡:", best_acc)

    # ==== 8. ç”»æŸå¤±æ›²çº¿ & å‡†ç¡®ç‡æ›²çº¿ ====
    epochs_range = range(1, len(history["train_loss"]) + 1)

    # Loss æ›²çº¿
    plt.figure(figsize=(6, 4))
    plt.plot(epochs_range, history["train_loss"], label="Train Loss")
    plt.plot(epochs_range, history["val_loss"], label="Val Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training & Validation Loss")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.savefig("loss_curve.png", dpi=200)
    plt.show()

    # æ¯ä¸ªå±æ€§çš„å‡†ç¡®ç‡æ›²çº¿
    plt.figure(figsize=(6, 4))
    for name, vals in history["acc"].items():
        plt.plot(epochs_range, vals, label=f"{name} Acc")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.title("Validation Accuracy per Attribute")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.savefig("acc_curve.png", dpi=200)
    plt.show()

    print("æŸå¤±æ›²çº¿å·²ä¿å­˜ä¸º loss_curve.pngï¼Œå‡†ç¡®ç‡æ›²çº¿å·²ä¿å­˜ä¸º acc_curve.png")




# ========== Windows å¤šè¿›ç¨‹ DataLoader å¿…å¤‡å…¥å£ ==========
if __name__ == "__main__":
    import torch.multiprocessing as mp
    try:
        mp.set_start_method("spawn", force=True)
    except RuntimeError:
        # å¯èƒ½å·²ç»è®¾ç½®è¿‡ start_methodï¼Œå¿½ç•¥å³å¯
        pass

    main()
